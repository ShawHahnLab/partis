[92mcache-parameters-data[0m            /home/dralph/work/partis/bin/partis cache-parameters --infname test/mishmash.fa --parameter-dir test/new-results/test/parameters/data --sw-cachefname test/new-results/test/parameters/data/sw-cache.yaml --n-max-queries -1 --seed 1 --n-procs 10
  note: running on a lot of sequences (1412) without setting --outfname. Which is ok, but there will be no persistent record of the results (except the parameter directory).
caching parameters
  vsearch: 1268 / 1412 v annotations (144 failed) with 177 v genes in 0.1 sec
    keeping 61 / 204 v genes
smith-waterman  (new-allele fitting)
  vsearch: 1264 / 1412 v annotations (148 failed) with 61 v genes in 0.2 sec
  removing old sw cache test/new-results/test/parameters/data/sw-cache.yaml
    running 10 procs for 1412 seqs
    running 13 procs for 71 seqs
      info for 1370 / 1412 = 0.970   (42 failed)
      kept 437 (0.309) unproductive
      removed 23 / 1370 = 0.02 duplicate sequences after trimming framework insertions (leaving 1347)
    water time: 2.0  (ig-sw 0.1  processing 0.2)
  no queries for allele finding
smith-waterman  (writing parameters)
  vsearch: 1264 / 1412 v annotations (148 failed) with 61 v genes in 0.2 sec
    running 10 procs for 1370 seqs
    running 13 procs for 29 seqs
      info for 1393 / 1412 = 0.987   (42 failed)
      kept 437 (0.309) unproductive
      removed 23 / 1370 = 0.02 duplicate sequences after trimming framework insertions (leaving 1347)
        writing sw results to test/new-results/test/parameters/data/sw-cache.yaml
    writing parameters to test/new-results/test/parameters/data/sw (2.1 sec)
    water time: 4.8  (ig-sw 2.9  processing 0.2)
  writing hmms (0.5 sec)
hmm
    skipping matches from 4 genes without enough counts: [95mh[0m[91mj[0m[95m4[0m[93m01[0m [95mh[0m[91mj[0m[95m6[0m[93m04[0m [95mh[0m[91mj[0m[95m4[0m[93m03[0m [95mh[0m[91mj[0m[95m6[0m[93m01[0m
    prepare_for_hmm: (0.1 sec)
    running 10 procs
                    calcd:         vtb 1347        fwd    0
             min-max time:  4.2 - 10.9 sec
    read output
    writing parameters to test/new-results/test/parameters/data/hmm (2.0 sec)
        processed 1347 hmm output lines with 1343 sequences in 1343 events  (4 failures)
            [91mwarning[0m skipped 4 invalid events
         infra time: 3.1
      hmm step time: 14.1
  writing hmms (0.4 sec)
      total time: 22.5
[92msimulate[0m                         /home/dralph/work/partis/bin/partis simulate --parameter-dir test/new-results/test/parameters/data --n-sim-events 500 --n-trees 500 --n-leaves 5 --seed 1 --n-procs 10 --outfname test/new-results/test/simu.yaml --indel-frequency 0.01 --indel-location v
simulating
      --> proc 1
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 187 seqs in 8.4s (7.7s of which was running bppseqgen)
      total time: 10.0

      --> proc 8
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 249 seqs in 8.9s (8.2s of which was running bppseqgen)
      total time: 10.4

      --> proc 9
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 241 seqs in 8.9s (8.1s of which was running bppseqgen)
      total time: 10.4

      --> proc 4
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 192 seqs in 9.1s (8.3s of which was running bppseqgen)
      total time: 10.6

      --> proc 7
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 212 seqs in 9.2s (8.4s of which was running bppseqgen)
      total time: 10.7

      --> proc 5
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 185 seqs in 9.2s (8.5s of which was running bppseqgen)
      total time: 10.7

      --> proc 2
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 235 seqs in 9.7s (8.8s of which was running bppseqgen)
      total time: 11.3

      --> proc 3
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 271 seqs in 9.7s (9.1s of which was running bppseqgen)
      total time: 11.3

      --> proc 0
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 218 seqs in 10.0s (9.4s of which was running bppseqgen)
      total time: 11.6

      --> proc 6
  note: getting germline sets from --initial-germline-dir, even though --reco-parameter-dir was also set
    made 50 events with 283 seqs in 10.3s (9.5s of which was running bppseqgen)
      total time: 11.8

   read 500 events with 2273 seqs from 10 .yaml files
      total time: 12.4
[92mcache-parameters-simu[0m            /home/dralph/work/partis/bin/partis cache-parameters --infname test/new-results/test/simu.yaml --parameter-dir test/new-results/test/parameters/simu --sw-cachefname test/new-results/test/parameters/simu/sw-cache.yaml --is-simu --seed 1 --n-procs 10
  note: running on a lot of sequences (2273) without setting --outfname. Which is ok, but there will be no persistent record of the results (except the parameter directory).
caching parameters
  vsearch: 2272 / 2273 v annotations (1 failed) with 83 v genes in 0.2 sec
    keeping 42 / 204 v genes
    [91mmissing[0m 14 simulation genes (counts): [95mh[0m[91mv[0m[95m1[0m[95m-24[0m[93m01[0m 0  [95mh[0m[91mv[0m[95m1[0m[95m-3[0m[93m02[0m 0  [95mh[0m[91mv[0m[95m1[0m[95m-45[0m[93m02[0m 0  [95mh[0m[91mv[0m[95m1[0m[95m-58[0m[93m01[0m 0  [95mh[0m[91mv[0m[95m1[0m[95m-69-2[0m[93m01[0m 0  [95mh[0m[91mv[0m[95m3[0m[95m-20[0m[93m01[0m 0  [95mh[0m[91mv[0m[95m3[0m[95m-30[0m[93m01[0m 0  [95mh[0m[91mv[0m[95m3[0m[95m-30[0m[93m02[0m 0  [95mh[0m[91mv[0m[95m3[0m[95m-NL1[0m[93m01[0m 1  [95mh[0m[91mv[0m[95m4[0m[95m-30-2[0m[93m05[0m 0  [95mh[0m[91mv[0m[95m4[0m[95m-30-4[0m[93m07[0m 0  [95mh[0m[91mv[0m[95m4[0m[95m-31[0m[93m02[0m 0  [95mh[0m[91mv[0m[95m4[0m[95m-34[0m[93m10[0m 0  [95mh[0m[91mv[0m[95m7[0m[95m-4-1[0m[93m02[0m 1
smith-waterman  (new-allele fitting)
  vsearch: 2271 / 2273 v annotations (2 failed) with 42 v genes in 0.4 sec
  removing old sw cache test/new-results/test/parameters/simu/sw-cache.yaml
    running 10 procs for 2273 seqs
    running 13 procs for 9 seqs
      info for 2273 / 2273 = 1.000   (0 failed)
      kept 1209 (0.532) unproductive
    water time: 3.8  (ig-sw 0.1  processing 0.1)
smith-waterman  (writing parameters)
  vsearch: 2271 / 2273 v annotations (2 failed) with 42 v genes in 0.4 sec
    running 10 procs for 2273 seqs
    running 13 procs for 9 seqs
      info for 2273 / 2273 = 1.000   (0 failed)
      kept 1209 (0.532) unproductive
        writing sw results to test/new-results/test/parameters/simu/sw-cache.yaml
    writing parameters to test/new-results/test/parameters/simu/sw (1.7 sec)
    water time: 7.1  (ig-sw 3.1  processing 0.3)
  writing hmms (0.7 sec)
hmm
    skipping matches from 2 genes without enough counts: [95mh[0m[91mj[0m[95m4[0m[93m01[0m [95mh[0m[91mj[0m[95m6[0m[93m01[0m
    prepare_for_hmm: (0.2 sec)
    running 10 procs
                    calcd:         vtb 2273        fwd    0
             min-max time:  3.6 - 3.8 sec
    read output
    writing parameters to test/new-results/test/parameters/simu/hmm (1.6 sec)
    writing parameters to test/new-results/test/parameters/simu/true (1.8 sec)
        processed 2273 hmm output lines with 2273 sequences in 2273 events  (0 failures)
         infra time: 6.6
      hmm step time: 10.8
  writing hmms (0.7 sec)
      total time: 25.9
[92mannotate-new-simu[0m                /home/dralph/work/partis/bin/partis annotate --infname test/new-results/test/simu.yaml --parameter-dir test/new-results/test/parameters/simu --sw-cachefname test/new-results/test/parameters/simu/sw-cache.yaml --plot-annotation-performance --is-simu --plotdir test/new-results/annotate-new-simu-annotation-performance --only-csv-plots --seed 1 --n-procs 10 --outfname test/new-results/annotate-new-simu.yaml
annotating
smith-waterman
  vsearch: 2270 / 2273 v annotations (3 failed) with 41 v genes in 0.4 sec
        reading sw results from test/new-results/test/parameters/simu/sw-cache.yaml
      info for 2273 / 2273 = 1.000   (0 failed, 0 duplicates)
      kept 1209 (0.532) unproductive
  plotting performance 
    [93mwarning[0m skipped annotation performance evaluation on 10 queries with different true and inferred net shm indel lengths: 514362951032283068 -2530715430849329531 -2719309947823100798 -6629434447850007203 -2641819200259491997 -8218517359196615418 5444993772841045241 -5601514340264548993 4085521097244289748 -8536116496363293073
(0.0 sec)
        water time: 1.5
hmm
    prepare_for_hmm: (0.2 sec)
    running 10 procs
                    calcd:         vtb 2273        fwd    0
             min-max time:  3.5 - 3.8 sec
    read output
  plotting performance (0.0 sec)
        processed 2273 hmm output lines with 2273 sequences in 2273 events  (0 failures)
         infra time: 2.2
      hmm step time: 6.1
      total time: 9.1
[92mmulti-annotate-new-simu[0m          /home/dralph/work/partis/bin/partis annotate --infname test/new-results/test/simu.yaml --parameter-dir test/new-results/test/parameters/simu --sw-cachefname test/new-results/test/parameters/simu/sw-cache.yaml --plot-annotation-performance --simultaneous-true-clonal-seqs --is-simu --plotdir test/new-results/multi-annotate-new-simu-annotation-performance --only-csv-plots --seed 1 --n-procs 10 --outfname test/new-results/multi-annotate-new-simu.yaml
annotating
smith-waterman
  vsearch: 2270 / 2273 v annotations (3 failed) with 41 v genes in 0.4 sec
        reading sw results from test/new-results/test/parameters/simu/sw-cache.yaml
      info for 2273 / 2273 = 1.000   (0 failed, 0 duplicates)
      kept 1209 (0.532) unproductive
  plotting performance 
    [93mwarning[0m skipped annotation performance evaluation on 10 queries with different true and inferred net shm indel lengths: 514362951032283068 -2530715430849329531 -2719309947823100798 -6629434447850007203 -2641819200259491997 -8218517359196615418 5444993772841045241 -5601514340264548993 4085521097244289748 -8536116496363293073
(0.0 sec)
        water time: 1.5
hmm
  [93mwarning[0m split apart 4 clusters that contained multiple cdr3 lengths (total clusters: 487 --> 491)
    prepare_for_hmm: (0.1 sec)
    running 10 procs
                    calcd:         vtb  491        fwd    0
             min-max time:  2.2 - 2.8 sec
    read output
  plotting performance (0.0 sec)
        processed 491 hmm output lines with 2273 sequences in 491 events  (0 failures)
         infra time: 1.8
      hmm step time: 4.7
      total time: 7.4
[92mpartition-new-simu[0m               /home/dralph/work/partis/bin/partis partition --infname test/new-results/test/simu.yaml --parameter-dir test/new-results/test/parameters/simu --sw-cachefname test/new-results/test/parameters/simu/sw-cache.yaml --n-max-queries 500 --n-precache-procs 10 --plot-annotation-performance --is-simu --persistent-cachefname test/new-results/cache-new-partition.csv --plotdir test/new-results/partition-new-simu-annotation-performance --only-csv-plots --seed 1 --n-procs 10 --outfname test/new-results/partition-new-simu.yaml
  --n-max-queries: stopped after reading 500 queries from input file
partitioning
smith-waterman
  vsearch: 500 / 500 v annotations (0 failed) with 30 v genes in 0.1 sec
        reading sw results from test/new-results/test/parameters/simu/sw-cache.yaml
      info for 500 / 500 = 1.000   (0 failed, 0 duplicates)
      kept 240 (0.480) unproductive
  plotting performance 
    [93mwarning[0m skipped annotation performance evaluation on 1 queries with different true and inferred net shm indel lengths: 514362951032283068
(0.0 sec)
        water time: 0.7
hmm
caching all 500 naive sequences
    prepare_for_hmm: (0.0 sec)
    running 10 procs
                no/empty cache file
                    calcd:         vtb 500        fwd   0
                   merged:       hfrac   0     lratio   0
             min-max time:  1.4 - 1.6 sec
      hmm step time: 1.8
   collapsed 500 queries into 261 clusters with identical naive seqs (0.0 sec)
261 clusters with 10 procs
    prepare_for_hmm: (0.0 sec)
       naive hfrac bounds: 0.015 0.090   (0.072 mean mutation in parameter dir test/new-results/test/parameters/simu/hmm)
    running 10 procs
          read from cache:  naive-seqs 500   logprobs   0
                    calcd:         vtb 110        fwd 150
                   merged:       hfrac  15     lratio  20
             min-max time:  0.8 - 1.4 sec
         infra time: 0.2
      hmm step time: 1.6
226 clusters with 7 procs
    prepare_for_hmm: (0.0 sec)
    running 7 procs
          read from cache:  naive-seqs 610   logprobs 150
                    calcd:         vtb  29        fwd  55
                   merged:       hfrac  15     lratio   6
             min-max time:  0.7 - 0.9 sec
         infra time: 0.2
      hmm step time: 1.1
205 clusters with 5 procs
    prepare_for_hmm: (0.0 sec)
    running 5 procs
          read from cache:  naive-seqs 639   logprobs 205
                    calcd:         vtb  28        fwd  63
                   merged:       hfrac  21     lratio   6
             min-max time:  0.6 - 1.9 sec
         infra time: 0.1
      hmm step time: 2.1
178 clusters with 3 procs
    prepare_for_hmm: (0.0 sec)
    running 3 procs
          read from cache:  naive-seqs 667   logprobs 268
                    calcd:         vtb  24        fwd  50
                   merged:       hfrac  22     lratio   2
             min-max time:  1.3 - 2.0 sec
         infra time: 0.1
      hmm step time: 2.1
154 clusters with 2 procs
    prepare_for_hmm: (0.0 sec)
    running 2 procs
          read from cache:  naive-seqs 693   logprobs 318
                    calcd:         vtb  23        fwd  65
                   merged:       hfrac  18     lratio   5
             min-max time:  2.7 - 3.1 sec
         infra time: 0.1
      hmm step time: 3.2
131 clusters with 2 procs
    prepare_for_hmm: (0.0 sec)
    running 2 procs
          read from cache:  naive-seqs 717   logprobs 383
                    calcd:         vtb  12        fwd  33
                   merged:       hfrac  10     lratio   2
             min-max time:  1.6 - 1.8 sec
         infra time: 0.1
      hmm step time: 1.9
119 clusters with 1 proc
    prepare_for_hmm: (0.0 sec)
    running 1 proc
          read from cache:  naive-seqs 729   logprobs 416
                    calcd:         vtb   4        fwd 100
                   merged:       hfrac   4     lratio   0
                     time:  6.5 sec
      hmm step time: 6.6
  [93mnote[0m not merging entire cpath history
      loop time: 18.7
getting annotations for final partition
    prepare_for_hmm: (0.0 sec)
    running 10 procs
                    calcd:         vtb 115        fwd   0
             min-max time:  0.7 - 1.3 sec
      hmm step time: 1.4
    read output
  plotting performance (0.0 sec)
        processed 115 hmm output lines with 500 sequences in 115 events  (0 failures)
  --only-csv-plots not implemented for partition plots, so returning without plotting
      total time: 23.4
[92mseed-partition-new-simu[0m          /home/dralph/work/partis/bin/partis partition --infname test/new-results/test/simu.yaml --parameter-dir test/new-results/test/parameters/simu --sw-cachefname test/new-results/test/parameters/simu/sw-cache.yaml --n-max-queries 500 --is-simu --persistent-cachefname test/new-results/cache-new-partition.csv --seed-unique-id 8127121293230795625 --seed 1 --n-procs 10 --outfname test/new-results/seed-partition-new-simu.yaml
  --n-max-queries: stopped after reading 500 queries from input file
partitioning
smith-waterman
  vsearch: 500 / 500 v annotations (0 failed) with 30 v genes in 0.1 sec
        reading sw results from test/new-results/test/parameters/simu/sw-cache.yaml
      info for 500 / 500 = 1.000   (0 failed, 0 duplicates)
      kept 240 (0.480) unproductive
      removed 458 / 500 = 0.92 sequences with cdr3 length different from seed sequence (leaving 42)
        water time: 0.2
hmm
   collapsed 42 queries into 20 clusters with identical naive seqs (0.0 sec)
20 clusters with 10 procs
    prepare_for_hmm: (0.0 sec)
       naive hfrac bounds: 0.015 0.090   (0.072 mean mutation in parameter dir test/new-results/test/parameters/simu/hmm)
    running 10 procs
          read from cache:  naive-seqs 734   logprobs 516
                    calcd:         vtb  16        fwd   0
                   merged:       hfrac   3     lratio   0
             min-max time:  0.1 - 0.2 sec
      hmm step time: 0.3
26 clusters with 7 procs
    prepare_for_hmm: (0.0 sec)
    running 7 procs
          read from cache:  naive-seqs 741   logprobs 516
                    calcd:         vtb   0        fwd   0
                   merged:       hfrac   0     lratio   0
             min-max time:  0.0 - 0.0 sec
    nothing to merge into /tmp/dralph/hmms/951354/hmm_cached_info.csv
      hmm step time: 0.1
23 clusters with 5 procs
    prepare_for_hmm: (0.0 sec)
    running 5 procs
          read from cache:  naive-seqs 741   logprobs 516
                    calcd:         vtb   0        fwd   0
                   merged:       hfrac   0     lratio   0
             min-max time:  0.0 - 0.0 sec
    nothing to merge into /tmp/dralph/hmms/951354/hmm_cached_info.csv
      hmm step time: 0.1
      removed 31 sequences in unseeded clusters, split 5 seeded clusters into 11 singletons, and merged these into 4 clusters with identical naive seqs
        new n_procs 1 (initial seqs/proc: 4.20   new seqs/proc: 4.00
4 clusters with 1 proc
    prepare_for_hmm: (0.0 sec)
    running 1 proc
          read from cache:  naive-seqs 741   logprobs 516
                    calcd:         vtb   3        fwd   7
                   merged:       hfrac   3     lratio   0
                     time:  0.3 sec
      hmm step time: 0.3
      loop time: 1.0
getting annotations for final partition
    prepare_for_hmm: (0.0 sec)
    running 3 procs
                    calcd:         vtb   3        fwd   0
             min-max time:  0.1 - 0.1 sec
      hmm step time: 0.1
    read output
        processed 3 hmm output lines with 11 sequences in 3 events  (0 failures)
  seed cluster size in best partition: 8,  excluding --queries-to-include: 7
      total time: 1.8
[92mvsearch-partition-new-simu[0m       /home/dralph/work/partis/bin/partis partition --infname test/new-results/test/simu.yaml --parameter-dir test/new-results/test/parameters/simu --sw-cachefname test/new-results/test/parameters/simu/sw-cache.yaml --naive-vsearch --n-max-queries 500 --is-simu --persistent-cachefname test/new-results/cache-new-partition.csv --seed 1 --n-procs 10 --outfname test/new-results/vsearch-partition-new-simu.yaml
  --n-max-queries: stopped after reading 500 queries from input file
partitioning
smith-waterman
  vsearch: 500 / 500 v annotations (0 failed) with 30 v genes in 0.1 sec
        reading sw results from test/new-results/test/parameters/simu/sw-cache.yaml
      info for 500 / 500 = 1.000   (0 failed, 0 duplicates)
      kept 240 (0.480) unproductive
        water time: 0.2
hmm
       naive hfrac bounds: 0.024 0.024   (0.072 mean mutation in parameter dir test/new-results/test/parameters/simu/hmm)
        collapsed 500 sequences into 261 unique naive sequences
    using hfrac bound for vsearch 0.024
    running vsearch 24 times (once for each cdr3 length class): . . . . . . . . . . . . . . . . . . . . . . . . 
      vsearch time: 1.5
getting annotations for final partition
    prepare_for_hmm: (0.0 sec)
    running 10 procs
                    calcd:         vtb 123        fwd   0
             min-max time:  0.7 - 1.0 sec
      hmm step time: 1.1
    read output
        processed 123 hmm output lines with 500 sequences in 123 events  (0 failures)
      total time: 3.3
